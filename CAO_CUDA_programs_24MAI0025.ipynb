{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1)Write a CUDA program to perform the vector addition and calculate its execution time using CUDA events. Use dynamic memory allocation for the arrays considered."
      ],
      "metadata": {
        "id": "CAmp03SJ-kHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsrVpz6f_Y92",
        "outputId": "f56cc87c-569e-4fb5-af54-08bc30db1efc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add1.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <time.h>\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "__global__ void vectorAdd(const float *A, const float *B, float *C, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < N) {\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Macro for checking CUDA errors\n",
        "#define CHECK_CUDA_ERROR(call)                               \\\n",
        "    do {                                                     \\\n",
        "        cudaError_t error = call;                            \\\n",
        "        if (error != cudaSuccess) {                          \\\n",
        "            fprintf(stderr, \"CUDA Error: %s (code %d), %s\\n\",\\\n",
        "                    cudaGetErrorString(error), error, #call);\\\n",
        "            exit(1);                                         \\\n",
        "        }                                                    \\\n",
        "    } while (0)\n",
        "\n",
        "int main() {\n",
        "    int N = 10 * 1024 * 1024;  // Vector size: 10 million elements\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    printf(\"Vector size: %d elements (%zu MB)\\n\", N, size / (1024 * 1024));\n",
        "\n",
        "    // Allocate host memory dynamically\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    if (h_A == NULL || h_B == NULL || h_C == NULL) {\n",
        "        fprintf(stderr, \"Host memory allocation failed\\n\");\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    // Seed random number generator and fill host arrays with random values\n",
        "    srand(time(NULL));\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = (float)rand() / RAND_MAX;\n",
        "        h_B[i] = (float)rand() / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory with error checking\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    CHECK_CUDA_ERROR(cudaMalloc((void **)&d_A, size));\n",
        "    CHECK_CUDA_ERROR(cudaMalloc((void **)&d_B, size));\n",
        "    CHECK_CUDA_ERROR(cudaMalloc((void **)&d_C, size));\n",
        "\n",
        "    // Copy data from host to device with error checking\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice));\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Define block and grid sizes\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (N + blockSize - 1) / blockSize;\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    CHECK_CUDA_ERROR(cudaEventCreate(&start));\n",
        "    CHECK_CUDA_ERROR(cudaEventCreate(&stop));\n",
        "\n",
        "    // Record the start event\n",
        "    CHECK_CUDA_ERROR(cudaEventRecord(start));\n",
        "\n",
        "    // Launch the kernel with error checking\n",
        "    vectorAdd<<<gridSize, blockSize>>>(d_A, d_B, d_C, N);\n",
        "    CHECK_CUDA_ERROR(cudaGetLastError());  // Check for kernel launch errors\n",
        "\n",
        "    // Record the stop event and synchronize\n",
        "    CHECK_CUDA_ERROR(cudaEventRecord(stop));\n",
        "    CHECK_CUDA_ERROR(cudaEventSynchronize(stop));\n",
        "\n",
        "    // Calculate and print elapsed time\n",
        "    float milliseconds = 0;\n",
        "    CHECK_CUDA_ERROR(cudaEventElapsedTime(&milliseconds, start, stop));\n",
        "    printf(\"Execution time: %f ms\\n\", milliseconds);\n",
        "\n",
        "    // Copy result from device to host with error checking\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Verify the result (optional for large sizes)\n",
        "    bool error_found = false;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        float expected = h_A[i] + h_B[i];\n",
        "        if (fabs(h_C[i] - expected) > 1e-5) {\n",
        "            printf(\"Error at index %d: %f != %f\\n\", i, h_C[i], expected);\n",
        "            error_found = true;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    if (!error_found) {\n",
        "        printf(\"Result verification passed!\\n\");\n",
        "    }\n",
        "\n",
        "    // Free device and host memory\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_A));\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_B));\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_C));\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    CHECK_CUDA_ERROR(cudaEventDestroy(start));\n",
        "    CHECK_CUDA_ERROR(cudaEventDestroy(stop));\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbEnustgD0TP",
        "outputId": "6c0a76c2-b046-4823-9137-03ba0d530d47"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_add1.cu -o vector_add1"
      ],
      "metadata": {
        "id": "NiB_yErkD7WB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wefk9Nu7_a3u",
        "outputId": "b59d9872-1eb0-4037-ecf2-3f67b3691892"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector size: 10485760 elements (40 MB)\n",
            "Execution time: 138.623108 ms\n",
            "Result verification passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)Write a CUDA program to perform the addition of two matrices and compare parallel and serial time. Use dynamic memory allocation for the arrays considered and CUDA events for the execution time."
      ],
      "metadata": {
        "id": "MCqNmnQzGpqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_add2.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <time.h>\n",
        "\n",
        "// CUDA kernel for matrix addition\n",
        "__global__ void matrixAdd(const float *A, const float *B, float *C, int width, int height) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < height && col < width) {\n",
        "        int idx = row * width + col;\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to perform matrix addition serially on the CPU\n",
        "void matrixAddSerial(const float *A, const float *B, float *C, int width, int height) {\n",
        "    for (int row = 0; row < height; row++) {\n",
        "        for (int col = 0; col < width; col++) {\n",
        "            int idx = row * width + col;\n",
        "            C[idx] = A[idx] + B[idx];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int width = 1024;   // Matrix width\n",
        "    int height = 1024;  // Matrix height\n",
        "    int N = width * height;  // Total number of elements\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    printf(\"Matrix size: %d x %d (%d elements)\\n\", width, height, N);\n",
        "\n",
        "    // Allocate host memory dynamically\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C_parallel = (float *)malloc(size);\n",
        "    float *h_C_serial = (float *)malloc(size);\n",
        "\n",
        "    // Check for successful host memory allocation\n",
        "    if (h_A == NULL || h_B == NULL || h_C_parallel == NULL || h_C_serial == NULL) {\n",
        "        fprintf(stderr, \"Host memory allocation failed\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Seed the random number generator and initialize matrices with random values\n",
        "    srand(time(NULL));\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = (float)rand() / RAND_MAX;\n",
        "        h_B[i] = (float)rand() / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_B, size);\n",
        "    cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid sizes\n",
        "    dim3 blockSize(16, 16);\n",
        "    dim3 gridSize((width + blockSize.x - 1) / blockSize.x, (height + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Record the start event for parallel execution\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Launch the kernel\n",
        "    matrixAdd<<<gridSize, blockSize>>>(d_A, d_B, d_C, width, height);\n",
        "\n",
        "    // Record the stop event for parallel execution\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // Calculate and print elapsed time for parallel execution\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    printf(\"Parallel execution time (CUDA): %f ms\\n\", milliseconds);\n",
        "\n",
        "    // Copy the result from device to host\n",
        "    cudaMemcpy(h_C_parallel, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Measure serial execution time using clock()\n",
        "    clock_t serial_start = clock();\n",
        "    matrixAddSerial(h_A, h_B, h_C_serial, width, height);\n",
        "    clock_t serial_end = clock();\n",
        "    double serial_time = 1000.0 * (serial_end - serial_start) / CLOCKS_PER_SEC;\n",
        "    printf(\"Serial execution time (CPU): %f ms\\n\", serial_time);\n",
        "\n",
        "    // Verify the result by comparing parallel and serial results\n",
        "    bool error_found = false;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (fabs(h_C_parallel[i] - h_C_serial[i]) > 1e-5) {\n",
        "            printf(\"Error at index %d: %f (parallel) != %f (serial)\\n\", i, h_C_parallel[i], h_C_serial[i]);\n",
        "            error_found = true;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    if (!error_found) {\n",
        "        printf(\"Result verification passed!\\n\");\n",
        "    }\n",
        "\n",
        "    // Free device and host memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C_parallel);\n",
        "    free(h_C_serial);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7XQpg7pGljd",
        "outputId": "98a6fb09-c0b3-4a65-c226-d5bb5e44c4b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_add2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_add2.cu -o matrix_add2"
      ],
      "metadata": {
        "id": "YNcyumUWHXC5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_add2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeZ2F4ENN23D",
        "outputId": "81be0ada-aa80-4985-ea32-751ffe90ee90"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size: 1024 x 1024 (1048576 elements)\n",
            "Parallel execution time (CUDA): 0.189184 ms\n",
            "Serial execution time (CPU): 5.639000 ms\n",
            "Result verification passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_add2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxBdrvWfHW6z",
        "outputId": "9699a106-37be-45bc-97e2-4c57c4e59d9f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size: 2048 x 2048 (4194304 elements)\n",
            "Parallel execution time (CUDA): 0.345152 ms\n",
            "Serial execution time (CPU): 25.398000 ms\n",
            "Result verification passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_add2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcKarIw4IUAp",
        "outputId": "4a84e78c-eed8-4de2-de7d-f3b38c69070c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size: 4096 x 4096 (16777216 elements)\n",
            "Parallel execution time (CUDA): 1.018976 ms\n",
            "Serial execution time (CPU): 91.000000 ms\n",
            "Result verification passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_add2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVlJH-xHMwUu",
        "outputId": "1361ff4b-4750-413a-d8f3-5ebc87a7e21f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix size: 8192 x 8192 (67108864 elements)\n",
            "Parallel execution time (CUDA): 3.504512 ms\n",
            "Serial execution time (CPU): 555.287000 ms\n",
            "Result verification passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bS46PQ4KOQRq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}